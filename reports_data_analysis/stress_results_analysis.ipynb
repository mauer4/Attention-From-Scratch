{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffb45b7",
   "metadata": {},
   "source": [
    "# Stress Test Surface Analysis\n",
    "\n",
    "This notebook loads stress test runs produced by `inference/stress_inference.py`, extracts run metadata (model, variant, GPU, etc.), and builds pivot tables plus 3D surface plots for tokens-per-second throughput and peak memory usage. Adjust the configuration cells below to point at specific runs or compare multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064619f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/bash_kernel/__main__.py\", line 3, in <module>\n",
      "\u001b[1;31m    IPKernelApp.launch_instance(kernel_class=BashKernel)\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "\u001b[1;31m    app.initialize(argv)\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 118, in inner\n",
      "\u001b[1;31m    return method(app, *args, **kwargs)\n",
      "\u001b[1;31m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 707, in initialize\n",
      "\u001b[1;31m    self.init_kernel()\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 555, in init_kernel\n",
      "\u001b[1;31m    kernel = kernel_factory(\n",
      "\u001b[1;31m             ^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/configurable.py\", line 583, in instance\n",
      "\u001b[1;31m    inst = cls(*args, **kwargs)\n",
      "\u001b[1;31m           ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/bash_kernel/kernel.py\", line 104, in __init__\n",
      "\u001b[1;31m    self._start_bash()\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/bash_kernel/kernel.py\", line 134, in _start_bash\n",
      "\u001b[1;31m    self.bashwrapper = IREPLWrapper(child, u'\\$', prompt_change, self.unique_prompt,\n",
      "\u001b[1;31m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/bash_kernel/kernel.py\", line 45, in __init__\n",
      "\u001b[1;31m    replwrap.REPLWrapper.__init__(self, cmd_or_spawn, orig_prompt,\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/pexpect/replwrap.py\", line 50, in __init__\n",
      "\u001b[1;31m    self.set_prompt(orig_prompt,\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/pexpect/replwrap.py\", line 61, in set_prompt\n",
      "\u001b[1;31m    self.child.expect(orig_prompt)\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\", line 354, in expect\n",
      "\u001b[1;31m    return self.expect_list(compiled_pattern_list,\n",
      "\u001b[1;31m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\", line 383, in expect_list\n",
      "\u001b[1;31m    return exp.expect_loop(timeout)\n",
      "\u001b[1;31m           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\", line 179, in expect_loop\n",
      "\u001b[1;31m    return self.eof(e)\n",
      "\u001b[1;31m           ^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\", line 122, in eof\n",
      "\u001b[1;31m    raise exc\n",
      "\u001b[1;31mpexpect.exceptions.EOF: End Of File (EOF). Exception style platform.\n",
      "\u001b[1;31m<pexpect.pty_spawn.spawn object at 0x7afa5176cd70>\n",
      "\u001b[1;31mcommand: /usr/bin/bash\n",
      "\u001b[1;31margs: [b'/usr/bin/bash', b'--rcfile', b'/usr/local/lib/python3.12/dist-packages/pexpect/bashrc.sh']\n",
      "\u001b[1;31mbuffer (last 100 chars): ''\n",
      "\u001b[1;31mbefore (last 100 chars): 'open terminal failed: terminal does not support clear\\r\\nduplicate session: ssh_tmux\\r\\n'\n",
      "\u001b[1;31mafter: <class 'pexpect.exceptions.EOF'>\n",
      "\u001b[1;31mmatch: None\n",
      "\u001b[1;31mmatch_index: None\n",
      "\u001b[1;31mexitstatus: None\n",
      "\u001b[1;31mflag_eof: True\n",
      "\u001b[1;31mpid: 32447\n",
      "\u001b[1;31mchild_fd: 62\n",
      "\u001b[1;31mclosed: False\n",
      "\u001b[1;31mtimeout: 30\n",
      "\u001b[1;31mdelimiter: <class 'pexpect.exceptions.EOF'>\n",
      "\u001b[1;31mlogfile: None\n",
      "\u001b[1;31mlogfile_read: None\n",
      "\u001b[1;31mlogfile_send: None\n",
      "\u001b[1;31mmaxread: 2000\n",
      "\u001b[1;31mignorecase: False\n",
      "\u001b[1;31msearchwindowsize: None\n",
      "\u001b[1;31mdelaybeforesend: 0.05\n",
      "\u001b[1;31mdelayafterclose: 0.1\n",
      "\u001b[1;31mdelayafterterminate: 0.1\n",
      "\u001b[1;31msearcher: searcher_re:\n",
      "\u001b[1;31m    0: re.compile('\\\\$'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.tri import LinearTriInterpolator, Triangulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf5b44",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def detect_reports_root() -> Path:\n",
    "    '''Best-effort search for the repo reports directory, regardless of notebook cwd.'''\n",
    "    candidates = []\n",
    "    cwd = Path.cwd().resolve()\n",
    "    candidates.append(cwd)\n",
    "    candidates.append(cwd / 'reports')\n",
    "    if cwd.parent != cwd:\n",
    "        candidates.append(cwd.parent)\n",
    "        candidates.append(cwd.parent / 'reports')\n",
    "    if len(cwd.parents) > 1:\n",
    "        candidates.append(cwd.parents[1])\n",
    "        candidates.append(cwd.parents[1] / 'reports')\n",
    "    for candidate in candidates:\n",
    "        if candidate is None:\n",
    "            continue\n",
    "        candidate = candidate.resolve()\n",
    "        reports_dir = candidate if candidate.name == 'reports' else candidate / 'reports'\n",
    "        if (reports_dir / 'stress').exists():\n",
    "            return reports_dir\n",
    "    raise FileNotFoundError('Could not locate reports/stress directory from current working directory.')\n",
    "\n",
    "REPORTS_ROOT = detect_reports_root()\n",
    "STRESS_ROOT = REPORTS_ROOT / 'stress'\n",
    "print(f'Using reports root: {REPORTS_ROOT}')\n",
    "print(f'Looking for runs under : {STRESS_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02b863",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def iter_run_directories(root: Path) -> List[Path]:\n",
    "    return sorted({path.parent for path in root.rglob('results.jsonl')})\n",
    "\n",
    "def load_run_records(run_dir: Path) -> List[Dict[str, Any]]:\n",
    "    metadata_path = run_dir / 'metadata.json'\n",
    "    results_path = run_dir / 'results.jsonl'\n",
    "    if not results_path.exists():\n",
    "        return []\n",
    "    metadata: Dict[str, Any] = {}\n",
    "    if metadata_path.exists():\n",
    "        metadata = json.loads(metadata_path.read_text())\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with results_path.open() as handle:\n",
    "        for line in handle:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('Total output lines'):\n",
    "                continue\n",
    "            record = json.loads(line)\n",
    "            result = record.get('result', {})\n",
    "            generation = result.get('generation', {})\n",
    "            runtime = result.get('runtime', {})\n",
    "            model_info = result.get('model', {})\n",
    "            gpu_info = runtime.get('gpu', {}) or {}\n",
    "            input_tokens = generation.get('input_length_tokens', record.get('target_input_tokens'))\n",
    "            new_tokens = generation.get('new_tokens')\n",
    "            if new_tokens is None and generation.get('output_length_tokens') is not None and input_tokens is not None:\n",
    "                new_tokens = generation['output_length_tokens'] - input_tokens\n",
    "            output_tokens = new_tokens if new_tokens is not None else record.get('target_output_tokens')\n",
    "            tokens_per_second = generation.get('tokens_per_second')\n",
    "            max_memory_mb = runtime.get('max_memory_megabytes')\n",
    "            if max_memory_mb is None and runtime.get('max_memory_bytes') is not None:\n",
    "                max_memory_mb = runtime['max_memory_bytes'] / (1024 ** 2)\n",
    "            rows.append({\n",
    "                'run_directory': str(run_dir),\n",
    "                'timestamp': result.get('timestamp'),\n",
    "                'model_name': metadata.get('model_name') or model_info.get('name'),\n",
    "                'model_variant': metadata.get('model_variant') or model_info.get('variant'),\n",
    "                'gpu_name': metadata.get('gpu_name') or gpu_info.get('name'),\n",
    "                'target_input_tokens': record.get('target_input_tokens'),\n",
    "                'target_output_tokens': record.get('target_output_tokens'),\n",
    "                'input_tokens': input_tokens,\n",
    "                'output_tokens': output_tokens,\n",
    "                'tokens_per_second': tokens_per_second,\n",
    "                'max_memory_mb': max_memory_mb,\n",
    "                'device': runtime.get('resolved_device'),\n",
    "                'dtype': runtime.get('dtype'),\n",
    "                'temperature': generation.get('temperature'),\n",
    "                'do_sample': generation.get('do_sample'),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def load_all_runs(stress_root: Path) -> pd.DataFrame:\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    for run_dir in iter_run_directories(stress_root):\n",
    "        records.extend(load_run_records(run_dir))\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(records)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df\n",
    "\n",
    "df = load_all_runs(STRESS_ROOT)\n",
    "print(f\"Loaded {len(df)} rows from {df['run_directory'].nunique() if not df.empty else 0} runs.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f071a1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    raise RuntimeError('No stress test results found. Run inference/stress_inference.py first.')\n",
    "\n",
    "run_dirs = sorted(df['run_directory'].unique())\n",
    "run_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c2cb8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Select a single run (latest by default). Override TARGET_RUN to inspect another directory.\n",
    "latest_run = df.sort_values('timestamp')['run_directory'].iloc[-1]\n",
    "TARGET_RUN = latest_run\n",
    "print(f'Using run: {TARGET_RUN}')\n",
    "run_df = df[df['run_directory'] == TARGET_RUN].copy()\n",
    "run_df.sort_values(['input_tokens', 'output_tokens']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b60555",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "meta = run_df[['model_name', 'model_variant', 'gpu_name', 'device', 'dtype']].drop_duplicates()\n",
    "print('Run metadata:')\n",
    "display(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55077c1c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "tokens_table = run_df.pivot_table(\n",
    "    index='output_tokens',\n",
    "    columns='input_tokens',\n",
    "    values='tokens_per_second',\n",
    "    aggfunc='mean'\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "memory_table = run_df.pivot_table(\n",
    "    index='output_tokens',\n",
    "    columns='input_tokens',\n",
    "    values='max_memory_mb',\n",
    "    aggfunc='max'\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "print('Tokens/sec surface table:')\n",
    "display(tokens_table)\n",
    "print('Peak memory (MB) surface table:')\n",
    "display(memory_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc31db",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def plot_surface(table: pd.DataFrame, title: str, z_label: str, cmap=cm.viridis) -> None:\n",
    "    if table.empty:\n",
    "        raise ValueError('Surface table is empty.')\n",
    "    x = table.columns.to_numpy()\n",
    "    y = table.index.to_numpy()\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = table.to_numpy(dtype=float)\n",
    "    Z_masked = np.ma.array(Z, mask=np.isnan(Z))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z_masked, cmap=cmap, edgecolor='none')\n",
    "    ax.set_xlabel('Input tokens')\n",
    "    ax.set_ylabel('Output tokens')\n",
    "    ax.set_zlabel(z_label)\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(surf, shrink=0.6, aspect=10, label=z_label)\n",
    "    plt.show()\n",
    "\n",
    "plot_surface(tokens_table, 'Tokens/sec surface', 'Tokens/sec', cmap=cm.viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bd8ad",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "plot_surface(memory_table, 'Peak memory surface', 'Max memory (MB)', cmap=cm.inferno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_INTERPOLATION = True\n",
    "GRID_POINTS = 50\n",
    "\n",
    "def interpolate_surface(run_frame: pd.DataFrame, value_column: str, grid_points: int = GRID_POINTS):\n",
    "    data = run_frame[['input_tokens', 'output_tokens', value_column]].dropna()\n",
    "    if data.shape[0] < 3:\n",
    "        raise ValueError('Need at least 3 data points to interpolate a surface.')\n",
    "    points = data[['input_tokens', 'output_tokens']].to_numpy(dtype=float)\n",
    "    values = data[value_column].to_numpy(dtype=float)\n",
    "    tri = Triangulation(points[:, 0], points[:, 1])\n",
    "    interpolator = LinearTriInterpolator(tri, values)\n",
    "    x_grid = np.linspace(points[:, 0].min(), points[:, 0].max(), grid_points)\n",
    "    y_grid = np.linspace(points[:, 1].min(), points[:, 1].max(), grid_points)\n",
    "    X, Y = np.meshgrid(x_grid, y_grid)\n",
    "    Z = interpolator(X, Y)\n",
    "    return X, Y, Z\n",
    "\n",
    "def plot_interpolated_surface(run_frame: pd.DataFrame, value_column: str, title: str, z_label: str, cmap=cm.plasma, grid_points: int = GRID_POINTS):\n",
    "    X, Y, Z = interpolate_surface(run_frame, value_column, grid_points)\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cmap, edgecolor='none')\n",
    "    ax.set_xlabel('Input tokens')\n",
    "    ax.set_ylabel('Output tokens')\n",
    "    ax.set_zlabel(z_label)\n",
    "    ax.set_title(f\"{title} (interpolated)\")\n",
    "    fig.colorbar(surf, shrink=0.6, aspect=10, label=z_label)\n",
    "    plt.show()\n",
    "\n",
    "if ENABLE_INTERPOLATION:\n",
    "    plot_interpolated_surface(run_df, 'tokens_per_second', 'Tokens/sec surface', 'Tokens/sec', cmap=cm.magma)\n",
    "    plot_interpolated_surface(run_df, 'max_memory_mb', 'Peak memory surface', 'Max memory (MB)', cmap=cm.cividis)\n",
    "else:\n",
    "    print('Interpolation disabled; set ENABLE_INTERPOLATION = True to show smoothed surfaces.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
